<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-118361649-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-118361649-1');
</script>
<title>explained.ai</title>
<!-- META -->
<!-- LinkedIn meta -->
<meta property='og:title' content="explained.ai"/>
<meta property='og:image' content="http://explained.ai/gradient-boosting/images/golf-MSE.png">
<meta property='og:description' content="Deep explanations of machine learning and related topics."/>
<meta property='og:url' content="http://explained.ai"/>

<!-- Facebook meta -->
<meta property="og:type" content="website" />

<!-- Twitter meta -->
<meta name="twitter:title" content="explained.ai">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@the_antlr_guy">
<meta name="twitter:creator" content="@the_antlr_guy">
<meta name="twitter:description" content="Deep explanations of machine learning and related topics.">
<meta name="twitter:image" content="http://explained.ai/gradient-boosting/images/golf-MSE.png">
<!-- END META -->
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
<link rel="stylesheet" type="text/css" href="css/style.css"/>
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
<div class="wrapper">
	<header>
		<h1>explained.ai</h1>
		Deep explanations of machine learning and related topics.<br><br><br>
		
		<span style="font-size: 90%;">
		<p>Website created by <a href="http://parrt.cs.usfca.edu">Terence Parr</a>.<br>
			<span style="float: left; padding-right: 8px; padding-top: 8px; padding-bottom: 2px;">
		<img style="float: left; padding: 3px; border: 1px solid; width: 80px;"  src="images/parrt.jpg"></span>
		Terence is a professor of computer science and was founding director of the <a href="https://www.usfca.edu/arts-sciences/graduate-programs/data-science">MS in data science program</a> at the University of San Francisco. While he is best known for creating the <a href="http://www.antlr.org">ANTLR parser generator</a>, Terence actually started out studying neural networks in grad school (1987). After 30 years of parsing, he's back to machine learning and really enjoys trying to explain complex topics deeply and in the simplest possible way. Follow <a href="https://twitter.com/the_antlr_guy"><tt>@the_antlr_guy</tt></a>.</p>
	</span>
		
	</header>
	<section>
		<h1 style="border-bottom: 1px solid #e5e5e5;">Articles</h1>

		<h2><a href="tensor-sensor/index.html">Clarifying exceptions and visualizing tensor operations in deep learning code</a> <font size=1>(October 2020)</font></h2>
		
		<a href="tensor-sensor/index.html"><img style="float:left; clear:left; padding: 3px;" src="tensor-sensor/images/teaser.png" width=210></a>
		<p>One of the biggest challenges when writing code to implement deep learning networks is getting all of the tensor (matrix and vector) dimensions to line up properly, even when using predefined network layers. This article describes a new library called <a href="https://github.com/parrt/tensor-sensor">TensorSensor</a> that clarifies exceptions by augmenting messages and visualizing Python code to indicate the shape of tensor variables. It works with Tensorflow, PyTorch, and Numpy, as well as higher-level libraries like Keras and fastai. See also the <a href="https://github.com/parrt/tensor-sensor/raw/master/talks/tensor-sensor.pdf">TensorSensor implementation slides</a> (PDF).</p>
		
	<h2><a href="rnn/index.html">Explaining RNNs without neural networks</a> <font size=1>(July 2020)</font></h2>
	
	<a href="rnn/index.html"><img style="float:left; clear:left; padding: 0px;" src="rnn/images/vid-fast.gif" width=210></a>
	<p>Vanilla recurrent neural networks (RNNs) form the basis of more sophisticated models, such as LSTMs and GRUs. But, sometimes the neural network metaphor makes it less clear exactly what's going on. This articles explains RNNs without neural networks, stripping them down to its essence&mdash;a series of vector transformations that result in embeddings for variable-length input vectors. I provide full PyTorch implementation notebooks that use just linear algebra and the autograd feature.</p>


		<h2><a href="regularization/index.html">A visual explanation for regularization of linear models</a> <font size=1>(May 2020)</font></h2>
		
		<a href="regularization/index.html"><img style="float:left; clear:left; padding: 0px;" src="regularization/images/lagrange-animation.gif" width=210></a>
		<p>Linear and logistic regression models are important because they are interpretable, fast, and form the basis of deep learning neural networks.  Unfortunately, linear models have a tendency to chase outliers in the training data, which often leads to models that don't generalize well to new data. To produce models that generalize better, we all know to regularize our models. While there are lots of articles on the mechanics of regularized linear models, we've lack a simple and intuitive explanation for what exactly is going on during regularization. The goal of this article is to explain how regularization behaves visually, dispelling some myths and answering important questions along the way.</p>

		<h2><a href="decision-tree-viz/index.html">How to visualize decision trees</a> <font size=1>(October 2018)</font></h2>
		
		<a href="decision-tree-viz/index.html"><img style="float:left; clear:left; padding: 5px;" src="decision-tree-viz/images/samples/wine-TD-2.svg" width=200></a>
		<p>(See <a href="https://www.youtube.com/watch?v=4FC1D9SuDBc&feature=youtu.be">video</a> discussion.) Decision trees are the fundamental building block of gradient boosting machines and Random Forests(tm), probably the two most popular machine learning models for structured data.  Visualizing decision trees is a tremendous aid when learning how these models work and when interpreting models.  Unfortunately, current visualization packages are rudimentary and not immediately helpful to the novice. For example, we couldn't find a library that visualizes how decision nodes split up the feature space.  So, we've created a general package called <a href="https://github.com/parrt/dtreeviz"><tt>dtreeviz</tt></a> for scikit-learn decision tree visualization and model interpretation.</p>
	
		<h2><a href="gradient-boosting/index.html">How to explain gradient boosting</a> <font size=1>(June 2018)</font></h2>
		
		<a href="gradient-boosting/index.html"><img style="float:left; clear:left; padding: 5px;" src="gradient-boosting/images/golf-MSE.png" width=200></a>
		<p>Gradient boosting machines (GBMs) are currently very popular and so it's a good idea for machine learning practitioners to understand how GBMs work. The problem is that understanding all of the mathematical machinery is tricky and, unfortunately, these details are needed to tune the hyper-parameters. (Tuning the hyper-parameters is required to get a decent GBM model unlike, say, Random Forests.) Our goal in this article is to explain the intuition behind gradient boosting, provide visualizations for model construction, explain the mathematics as simply as possible, and answer thorny questions such as why GBM is performing &ldquo;gradient descent in function space.&rdquo;</p>
	
		<h2><a href="matrix-calculus/index.html">The Matrix Calculus You Need For Deep Learning</a> <font size=1>(February 2018)</font></h2>


		<a href="matrix-calculus/index.html"><img style="float:left; clear:left; padding: 5px;"  src="matrix-calculus/images/neuron.png" width=200></a>
			<p>This article explains all of the matrix calculus you need in order to understand the training of deep neural networks. Most of us last saw calculus in school, but derivatives are a critical part of machine learning, particularly deep neural networks, which are trained by optimizing a loss function. Pick up a machine learning paper or the documentation of a library such as PyTorch and calculus comes screeching back into your life like distant relatives around the holidays. And it's not just any old scalar calculus that pops up--you need differential matrix calculus, the shotgun wedding of linear algebra and multivariate calculus. (<a href="https://arxiv.org/abs/1802.01528">printable PDF at arxiv.org</a>)</p>
			

		<h2><a href="rf-importance/index.html">Beware Default Random Forest Importances</a> <font size=1>(March 2018)</font></h2>
		
		<a href="rf-importance/index.html"><img style="float:left; clear:left; padding: 5px;"  src="rf-importance/images/cls_dflt_random_annotated.png" width=200></a>
		<p>Training a model that accurately predicts outcomes is great, but most of the time you don't just need predictions, you want to be able to interpret your model. The problem is that the scikit-learn Random Forest feature importance and R's default Random Forest feature importance strategies are biased. To get reliable results in Python, use permutation importance, provided here and in our <a href="https://github.com/parrt/random-forest-importances">rfpimp</a> package (via pip). For R, use importance=T in the Random Forest constructor then type=1 in R's importance() function. </p>
		
		<h1 style="margin:50 0 20px; border-bottom: 1px solid #e5e5e5;">Books</h1>
		
		<h2 style="margin:0 0 0px;"><a href="https://mlbook.explained.ai">The Mechanics of Machine Learning</a></h2>
		
		<a href="http://parrt.cs.usfca.edu">Terence Parr</a> and <a href="http://www.fast.ai/about/#jeremy">Jeremy Howard</a><br><br>
		
		<p>This book is a primer on machine learning for programmers trying to get up to speed quickly. You'll learn how machine learning works and how to apply it in practice. We focus on just a few powerful models (algorithms) that are extremely effective on real problems, rather than presenting a broad survey of machine learning algorithms as many books do. Co-author Jeremy used these few models to become the #1 competitor for two consecutive years at Kaggle.com. This narrow approach leaves lots of room to cover the models, training, and testing in detail, with intuitive descriptions and full code implementations.</p>
		
<p><i>This is a book in progress; 9 chapters posted</i>.</p>


		<h1 style="margin:50 0 20px; border-bottom: 1px solid #e5e5e5;">Academic papers</h1>

		<h2><a href="https://arxiv.org/abs/2006.04750">Nonparametric Feature Impact and Importance</a> <font size=1>(June 2020)</font></h2>
		<a href="https://arxiv.org/abs/2006.04750"><img style="float:left; clear:left; padding: 5px;" src="https://github.com/parrt/stratx/raw/master/images/rent-topk-RF-Impact.png" width="200"></a>
		<p>
			Practitioners use feature importance to rank and eliminate weak predictors during model development in an effort to simplify models and improve generality. Unfortunately, they also routinely conflate such feature importance measures with feature impact, the isolated effect of an explanatory variable on the response variable. This can lead to real-world consequences when importance is inappropriately interpreted as impact for business or medical insight purposes. The dominant approach for computing importances is through interrogation of a fitted model, which works well for feature selection, but gives distorted measures of feature impact. In this paper, we give mathematical definitions of feature impact and importance, derived from partial dependence curves, that operate directly on the data. To assess quality, we show that features ranked by these definitions are competitive with existing feature selection techniques using three real data sets for predictive tasks.			
		</p>
		
		<h2><a href="https://arxiv.org/abs/1907.06698">Partial Dependence through Stratification</a> <font size=1>(July 2019)</font></h2>
		<a href="https://arxiv.org/abs/1907.06698"><img style="float:left; clear:left; padding: 5px;" src="https://github.com/parrt/stratx/raw/master/images/bulldozer_YearMade_stratpd.png" width=200></a>
		<p>Partial dependence curves (FPD) introduced by Friedman, are an important model interpretation tool, but are often not accessible to business analysts and scientists who typically lack the skills to choose, tune, and assess machine learning models. It is also common for the same partial dependence algorithm on the same data to give meaningfully different curves for different models, which calls into question their precision. Expertise is required to distinguish between model artifacts and true relationships in the data.  In this paper, we contribute methods for computing partial dependence curves, for both numerical (StratPD) and categorical explanatory variables (CatStratPD), that work directly from training data rather than predictions of a model. Our methods provide a direct estimate of partial dependence, and rely on approximating the partial derivative of an unknown regression function without first fitting a model and then approximating its partial derivative. We investigate settings where contemporary partial dependence methods--including FPD, ALE, and SHAP methods--give biased results. Furthermore, we demonstrate that our approach works correctly on synthetic and plausibly on real data sets. Our goal is not to argue that model-based techniques are not useful. Rather, we hope to open a new line of inquiry into nonparametric partial dependence. <a href="https://github.com/parrt/stratx">Complete source code repo</a> is available and you can "<tt>pip install stratx</tt>".</p>

		<h2><a href="http://www.antlr.org/papers/codebuff.pdf">Towards a Universal Code Formatter through Machine Learning</a> <font size=1>(October 2016)</font></h2>
		
		<a href="http://www.antlr.org/papers/codebuff.pdf"><img style="float:left; clear:left; padding: 5px;"  src="images/codebuff-tree.png" width=200></a>
		<p>This academic paper describes a tool called <a href="https://github.com/antlr/codebuff">CodeBuff</a> (github repo) that automatically derives code formatters for any given programming language without intervention from a language expert, abstracting the formatting rules from a representative corpus. CodeBuff illustrates how even the simplest machine learning model, <i>k</i>-nearest neighbor in this case, can perform very well given sufficiently rich features.</p>

		<h1 style="margin:50 0 20px; border-bottom: 1px solid #e5e5e5;">Videos</h1>

		<h2 style="margin:0 0 0px;"><a href="https://slideslive.com/38957211/ya-gotta-make-it-obvious">Ya gotta make it obvious</a><br><font size=1>May 2021</font></h2>

		<a href="https://slideslive.com/38957211/ya-gotta-make-it-obvious"><img style="float:left; clear:left; padding: 8px;" src="images/make-obvious.png" width=200></a>
		<p>This is a talk from <a href="https://rethinkingmlpapers.github.io/">Rethinking ML Papers workshop at ICLR 2021</a> with my thoughts on presenting complex technical subjects, including what's wrong w/traditional academic output. Some bullet points:  "<i>Peer review and our egos ... are the enemy of simplicity and clarity</i>," "<i>Try to illuminate not impress!</i>," and "<i>What we need: correct, deep, and obvious</i>".

		<h2 style="margin:0 0 0px;"><a href="https://www.youtube.com/watch?v=4FC1D9SuDBc&feature=youtu.be">The visual interpretation of decision trees</a><br><font size=1>November 2018</font></h2>

		<a href="https://www.youtube.com/watch?v=4FC1D9SuDBc&feature=youtu.be"><img style="float:left; clear:left; padding: 8px;" src="images/dtreeviz-parrt.png" width=200></a>
		<p><b>Subtitle</b>: How to lead a fulfilling life by being dissatisfied.
		<p>This video is a lecture from the <a href="https://www.meetup.com/USF-Seminar-Series-in-Data-Science">USF seminar series in data science</a>, describing the article <a href="https://explained.ai/decision-tree-viz/index.html">How to visualize decision trees</a> and Python package <a href="https://github.com/parrt/dtreeviz"><tt>dtreeviz</tt></a>.
		<p>I finish up the lecture with some advice about how dissatisfaction can spur innovation.

		<h1 style="margin:50 0 20px; border-bottom: 1px solid #e5e5e5;">Libraries</h1>
		
		<h2 style="clear:left;"><a href="https://github.com/parrt/dtreeviz"><tt>dtreeviz</tt></a></h2>
		
		<a href="https://github.com/parrt/dtreeviz"><img style="float:left; clear:left; padding: 5px;" src="http://explained.ai/decision-tree-viz/images/samples/boston-TD-3-X.svg" width=200></a>
		<p><a href="https://github.com/parrt/dtreeviz"><tt>dtreeviz</tt></a> is a python library for decision tree visualization and model interpretation inspired by an animation from R2D3: <a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">A visual introduction to machine learning</a>.  With <tt>dtreeviz</tt>, you can visualize how the feature space is split up at decision nodes, how the training samples get distributed in leaf nodes and how the tree makes predictions for a specific observation. These operations are critical to for understanding how classification or regression decision trees work. See article <a href="http://explained.ai/decision-tree-viz/index.html">How to visualize decision trees</a>.</p>

		<h2><a href="https://github.com/parrt/random-forest-importances"><tt>rfpimp</tt></a></h2>
		
		<a href="https://github.com/parrt/random-forest-importances"><img style="float:left; clear:left; padding: 5px;" src="rf-importance/images/corrheatmap.svg" width=200></a>
		<p>The scikit-learn Random Forest feature importance and R's default Random Forest feature importance strategies are biased. To get reliable results in Python, use permutation importance, provided here and in our rfpimp package (via pip).</p>
		
		
		<h2 style="clear:left;"><a href="https://github.com/parrt/lolviz"><tt>lolviz</tt></a></h2>
		
		<a href="https://github.com/parrt/lolviz"><img style="float:left; clear:left; padding: 5px;" src="https://github.com/parrt/lolviz/raw/master/images/callstack.png" width=200></a>
		<p>A simple Python data-structure visualization tool that started out as a List Of Lists (lol) visualizer but now handles arbitrary object graphs, including function call stacks! lolviz tries to look out for and format nicely common data structures such as lists, dictionaries, linked lists, and binary trees. As of 1.4, lolviz also supports the display of <a href="http://www.numpy.org/">numpy</a> 1D/2D <tt>ndarray</tt>s. This package is primarily for use in teaching and presentations with Jupyter notebooks, but could also be used for debugging data structures, such as decision trees or graphs.</p>

		<h2 style="clear:left;"><a href="https://github.com/parrt/autodx"><tt>autodx</tt></a></h2>
		
		<a href="https://github.com/parrt/lolviz"><img style="float:left; clear:left; padding: 5px;" src="https://github.com/parrt/lolviz/raw/master/images/callstack.png" width=200></a>
		<p>Simple automatic differentiation via Python operator overloading built to learn how automatic differentiation works, but this repo is more of a junk drawer rather than a library that's ready to use the moment.</p>

		<h1 style="margin:50 0 20px; border-bottom: 1px solid #e5e5e5;">Resources</h1>
		<h2><a href="/statspeak/index.html">Statisticians say the darndest things</a></h2>
		
		<p>The nomenclature used by statisticians is peculiar to say the least, so I thought I'd put this document together. It's meant as good-natured teasing of my friends who are statisticians, but it might actually be useful to other computer scientists.</p>
				
	</section>
	<footer>
<p style="clear: left;">Copyright &copy; 2018 by Terence Parr.<br>All rights reserved.</p>
      </footer>
</div>
</body>
</html>

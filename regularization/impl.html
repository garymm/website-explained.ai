<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LKK44VKP71"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LKK44VKP71');
</script>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
<link rel="stylesheet" type="text/css" href="css/article.css"/>
<title>How we express regularization in practice</title>
<!-- META -->
<!-- LinkedIn meta -->
<meta property='og:title' content="A visual explanation of linear model regularization"/>
<meta property='og:image' content="http://explained.ai/regularization/images/reg3D.svg">
<meta property='og:description' content=""/>
<meta property='og:url' content="http://explained.ai/regularization/index.html"/>

<!-- Facebook meta -->
<meta property="og:type" content="article" />

<!-- Twitter meta -->
<meta name="twitter:title" content="A visual explanation of linear model regularization">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@the_antlr_guy">
<meta name="twitter:creator" content="@the_antlr_guy">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="http://explained.ai/regularization/images/reg3D.svg">
<!-- END META -->
</head>
<body>
<div class="watermark">
<i><a href='http://explained.ai/regularization/index.html'>Main article</a><br>Brought to you by <a href='http://explained.ai'>explained.ai</a></i><br>
</div>

<h1>4 How we express regularization in practice</h1>

<p></p>

<p><a href="https://www.linkedin.com/in/terence-parr/">Terence Parr</a></p>

<p style="font-size: 80%">(Terence is a tech lead at Google and ex-Professor of computer/data science in <a href="https://www.usfca.edu/arts-sciences/graduate-programs/data-science">University of San Francisco's MS in Data Science program</a>. You might know Terence as the creator of the ANTLR parser generator.)</p>



<div id="toc">
<p class="toc_title">Contents</p>
<ul>
	<li><a href="#sec:4.1">A quick hard constraint regularization recap</a>
	<ul>
	</ul>
	</li>
	<li><a href="#sec:4.2">Recasting hard constraints as soft constraints</a>
	<ul>
	</ul>
	</li>
	<li><a href="#sec:4.3">Wrapping up</a>
	<ul>
	</ul>
	</li>

</ul>
</div>


<p>If we think about regularization as just constraining how close we can get to the true loss function minimum, regularization is not that hard to understand (assuming you understand linear models, of course). Conceptually, regularization uses a circle (L2) or diamond (L1) as a hard constraint. If the loss function minimum location is outside the constraint region, the regularized coefficients will appear somewhere on the boundary of the constraint region. We saw this earlier, and depicted the constraint region as a simple gray circle for L2 regularization:</p>

<p><center>
<img src="images/reg3D.svg" width="30%">
</center></p>

<p>So, this is conceptually how things work, but it's not easy/efficient to implement regularization this way.  Let's quickly review the mathematics notation that describes the conceptual constraints; then we can move on to how we actually express regularization for implementation purposes.</p>

<p>(The <a href="https://github.com/parrt/website-explained.ai/tree/master/regularization/code">code to generate all images</a> is available.)</p>



<h2 id="sec:4.1">4.1 A quick hard constraint regularization recap</h2>


<p>We want to fit a linear model with three coefficients and two variables to some data:</p>

<p><img style="vertical-align: -3.0765pt;" src="images/eqn-A2EFEA5E2E5392BC522CD98A7E4D60AF-depth002.93.svg"></p>

<p>To do that, we want to pick <img style="vertical-align: -4.0424995pt;" src="images/eqn-35E985D710477A356D19570D41E41111-depth003.85.svg"> coefficients that minimize the loss function; the loss function just says how good of a fit the equation is to the training data. The mean squared error is the usual loss function and it is the average squared difference between the known true <img style="vertical-align: -2.7825pt;" src="images/eqn-4BE66AD2CF5C98540DB20BD7DF0C0413-depth002.65.svg"> values and our predictions, <img style="vertical-align: -2.7825pt;" src="images/eqn-11477AE3C754D1E3F7950B3DAA7173A8-depth002.65.svg">:</p>

<div><img class="blkeqn" src="images/blkeqn-171957764B81187DA92D2CD96BAC16C5.svg" alt="" width=""></div>

<p>By substituting <img style="vertical-align: -2.7825pt;" src="images/eqn-11477AE3C754D1E3F7950B3DAA7173A8-depth002.65.svg"> into the loss function, we get the typical equation that describes fitting a linear model:</p>

<div><img class="blkeqn" src="images/blkeqn-8E596A7926E3A025A7561329C77F08A3.svg" alt="" width=""></div>

<p>To add a hard constraint, we add &ldquo;subject to&rdquo; language. For L2 it, looks like this:</p>

<div><img class="blkeqn" src="images/blkeqn-2397AA44B08134C3360E1FC017AB951B.svg" alt="" width=""></div>

<p>and, for L1, it looks like:</p>

<div><img class="blkeqn" src="images/blkeqn-1D6752188BA1DBC5C472F5D5B2CBAB00.svg" alt="" width=""></div>



<h2 id="sec:4.2">4.2 Recasting hard constraints as soft constraints</h2>


<p>To implement a loss function with a hard constraint, we could use a gradient descent minimization approach as usual. The problem is that, at each step moving us closer to the loss function minimum, we'd need an IF-statement asking if <img style="vertical-align: -3.4125pt;" src="images/eqn-0A759A3F5F6C618F914BA43BA1D51535-depth003.25.svg"> had exceeded the constraint. Certainly that would work, but it would definitely slow down the computation. (Insert discussion of branching, pipeline bubbles, etc... on modern processors). </p>

<p>An alternative approach is to convert the constraint into just another term of the loss function, but at the cost of making it a <i>soft constraint</i>, not a hard constraint. For L2, replace &ldquo;subject to <img style="vertical-align: -3.6225pt;" src="images/eqn-CDCD7E172D37F6A2652CFE9C7501E062-depth003.45.svg">&rdquo; with <img style="vertical-align: -3.6225pt;" src="images/eqn-D8A89CBA8205C0AD4087DA0EECEFEE3C-depth003.45.svg">:</p>

<div><img class="blkeqn" src="images/blkeqn-BBFF8AFED12D79218469FE0EC1ECB3AE.svg" alt="" width=""></div>

<p>and, for L1, we get the analogous:</p>

<div><img class="blkeqn" src="images/blkeqn-B5A422FD5CF83B5CADD4139B5CA46AAD.svg" alt="" width=""></div>

<p>This replacement is mathematically legal because there exists a <img style="vertical-align: -0.5pt;" src="images/eqn-C6A6EB61FD9C6C913DA73B3642CA147D-depth000.22.svg"> value that is equivalent to some <span class=eqn>t</span> for the hard constraint, per the magic of <a href="https://en.wikipedia.org/wiki/Lagrange_multiplier">Lagrange multipliers</a>. <img style="vertical-align: -0.5pt;" src="images/eqn-C6A6EB61FD9C6C913DA73B3642CA147D-depth000.22.svg"> is unknown just like <span class=eqn>t</span>, but at least now we have a single function to minimize, rather than a function subject to a constraint. To find <img style="vertical-align: -0.5pt;" src="images/eqn-C6A6EB61FD9C6C913DA73B3642CA147D-depth000.22.svg">, we try a bunch of <img style="vertical-align: -0.5pt;" src="images/eqn-C6A6EB61FD9C6C913DA73B3642CA147D-depth000.22.svg"> values and see which one gives us a regularized linear model that has the smallest validation set error.</p>

<p>The loss function now has two terms, one for MSE and one for throttling down coefficient values. Visually, as shown in <b>Figure 4.1</b>, we get two bowl-shaped quadratic surfaces, where the soft constraint is orange and centered at the origin (0,0). The larger the coefficient(s), the higher the orange penalty term and, hence, the higher the loss function. It keeps coefficients low, like a hard constraint, but not at a fixed boundary.  Larger coefficients are just more &ldquo;expensive.&rdquo; </p>
<span class=figure><center>
<table style="">
<thead>
<tr>
<th align=center valign=top >(a)</th><th align=center valign=top >(b)</th>
</tr>
</thead>
<tbody>
<tr>
<td align=center valign=top>

<center>
<center>
<img src="images/constraint3D.svg" width="100%">
</center>
</center>

</td><td align=center valign=top>

<center>
<center>
<img src="images/constraint2D.svg" width="100%">
</center>
</center>

</td>
</tr>
</tbody>
</table>
</center><center><b>Figure 4.1</b>. MSE loss function + soft constraint to penalize coefficients that get too big.</center></span>
<p>Somewhere along the dotted line in the 3D to 2D projection of <b>Figure 4.1</b> (b), our loss function optimizer will find coordinates for the minimal value. The big X marks the ordinary loss function location minimum <img style="vertical-align: -3.4125pt;" src="images/eqn-E3B16E03DDCF47574AFEFFC59BBDA08B-depth003.25.svg"> and (0,0) is the center of the penalty term. As we move away from (0,0) the penalty term is going to get large very quickly, because the penalty term is a quadratic, <img style="vertical-align: -3.6225pt;" src="images/eqn-D8A89CBA8205C0AD4087DA0EECEFEE3C-depth003.45.svg">. The net effect is that regularization raises the complete loss &ldquo;bowl&rdquo; and pulls the minimum loss location closer to origin. </p>

<p><i>What happens if we set</i> <img style="vertical-align: -0.5pt;" src="images/eqn-EAFDD30D85348E648C8891CF5D3F9681-depth000.22.svg">? The penalty turn disappears and we get the original loss function.</p>

<p><i>What happens if we set it very high</i>? That means that only coefficients very close to (0,0) will be suitable because the ordinary loss function bowl has effectively been pulled very close to (0,0).</p>

<p><b>Figure 4.2</b> illustrates how the complete loss function, with both ordinary loss function and penalty term, changes as <img style="vertical-align: -0.5pt;" src="images/eqn-C6A6EB61FD9C6C913DA73B3642CA147D-depth000.22.svg"> moves from 0 to 6.0. The training data is the same; the only thing changing is <img style="vertical-align: -0.5pt;" src="images/eqn-C6A6EB61FD9C6C913DA73B3642CA147D-depth000.22.svg">. The complete loss function moves upwards and towards the origin. (It's not the best animation, but it stretched my <span class=inlinecode>matplotlib</span> knowledge to the limit!)</p>
<span class=figure>

<center>
<center>
<img src="images/lagrange-animation.gif" width="60%">
</center>
</center>

<center><b>Figure 4.2</b>. MSE loss function + soft constraint as lambda varies from 0 to 6. This simulates the exact same training data set; we're just changing lambda.</center></span>
<p>Turning to L1 briefly, the exact same soft constraint mechanism is at play except that, instead of the bowl shape in <b>Figure 4.1</b> (a), L1 uses an upside down pyramid with its point stuck into the origin. The pyramid base gets larger and larger away from the origin. The original loss function is again raised and moved towards the origin, but does so more slowly because the L1 penalty term is linear in the coefficients not a quadratic like L2.</p>

<p>The difference between L1 and L2 is most pronounced when the coefficients become less than 1.0.  Imagine that <img style="vertical-align: -3.0765pt;" src="images/eqn-FFA1FEEFCB292880CD9F7E1E1E90BD07-depth002.93.svg"> and <img style="vertical-align: -0.5pt;" src="images/eqn-F37014F19EBE7F9ED581407A1AD7534A-depth000.22.svg"> for simplicity. L1's penalty term <img style="vertical-align: -3.4125pt;" src="images/eqn-2DFF5637CBEFDFF5AEA95CD86F2F9FBE-depth003.25.svg"> but L2's penalty term <img style="vertical-align: -3.6225pt;" src="images/eqn-7A13C21D2DAAA033F4C933A7E73A1B62-depth003.45.svg">, which is an order of magnitude smaller.  That implies that L1 has little problem pushing the loss function up and towards the origin until one or more coefficients become zero. L2, on the other hand, requires larger and larger <img style="vertical-align: -0.5pt;" src="images/eqn-C6A6EB61FD9C6C913DA73B3642CA147D-depth000.22.svg"> as it struggles to add loss to the complete loss function. When the coefficients get very close to zero, say, <img style="vertical-align: -3.0765pt;" src="images/eqn-7B2366E2B6C700F0F018E6E07D1EB51D-depth002.93.svg">, the L2 penalty term is adding just 0.000002 to the overall loss function, whereas, L1 adds 0.002. The effect is that the L2 coefficients do not move towards the origin very quickly when less than 1.</p>

<p>To summarize, regularization conceptually uses a hard constraint to prevent coefficients from getting too large. For implementation purposes, however, we convert the &ldquo;subject to&rdquo; hard constraint to a soft constraint by adding the constraint as a term to the loss function. This term is a soft constraint because there is no threshold or clipping; larger coefficients are simply more expensive. The effect is to shift the ordinary loss function &ldquo;bowl&rdquo; upwards and the loss function minimum towards the origin.</p>



<h2 id="sec:4.3">4.3 Wrapping up</h2>


<p>So, now you've got it all!  You know how regularization works conceptually, how L1 and L2 differ in terms of getting zero coefficients, and how we actually express regularization and practice. Congratulations if you've made it all this way!  If you'd like to learn how we use gradient descent to implement regularization, take a look at a project I give my first semester graduate students in data science: <a href="https://github.com/parrt/msds621/raw/master/projects/linreg/linreg.pdf">Using gradient descent to fit regularized linear models</a>.</p>

<p>The end.</p>



</body>
</html>
